torch.backends.cuda.matmul.allow_tf32 = True
torch.set_float32_matmul_precision("high")  # CUDA >= 11.8 / PyTorch 2.x

# Prefer Flash / Mem-Efficient SDPA over the slower math kernel
torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False, enable_mem_efficient=True)
